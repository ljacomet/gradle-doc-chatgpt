{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "\n",
    "This first section installs all the dependencies we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "%pip install tiktoken==0.3.3\n",
    "%pip install openai==0.27.2\n",
    "%pip install langchain==0.0.134\n",
    "%pip install python-dotenv==1.0.0\n",
    "%pip install faiss-cpu==1.7.3\n",
    "\n",
    "# Make sure required folders exist\n",
    "import os\n",
    "folder_paths = ['resources', 'output']\n",
    "\n",
    "for path in folder_paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our OpenAI API Key\n",
    "\n",
    "You will need an OpenAI API key for these examples to work.\n",
    "Currently, only paid plans are available.\n",
    "\n",
    "Key is sourced from a `.keys` file located in the project folder and then exposed as an env var.\n",
    "The content of the `.keys` file should be:\n",
    "```\n",
    "OPENAI_API_KEY=<secret_key>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "api_keys = dotenv_values('.keys')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = api_keys['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean Gradle single page documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Gradle single page HTML documentation and clean it up\n",
    "# TODO Replace manual clean-up of removing all header content, css and TOC by automated removals\n",
    "import re\n",
    "\n",
    "# Load a local html file\n",
    "with open('resources/gradle.html', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove all HTML tags\n",
    "cleaned_gradle = re.sub(r'<[^>]*>', '', text)    \n",
    "\n",
    "# Remove blank lines\n",
    "cleaned_gradle = re.sub(r'^\\s*$', '', cleaned_gradle, flags=re.MULTILINE)\n",
    "\n",
    "# Remove the \\n\\n that are left over\n",
    "cleaned_gradle = cleaned_gradle.replace('\\n\\n', '\\n')\n",
    "\n",
    "# Save the text\n",
    "with open('output/gradle_cleaned.txt', 'w') as f:\n",
    "    f.write(cleaned_gradle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our content in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([cleaned_gradle])\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed and store the texts\n",
    "This uses an in-memory vector database: https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embed and store the texts\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now wire these with OpenAI\n",
    "Lots of mystery in there for now ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "query = \"How do you add an artifact transform and make sure it executes? Add an example\"\n",
    "\n",
    "search_results = vectorstore.similarity_search(query)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "result = chain.run(input_documents=search_results, question=query)\n",
    "\n",
    "with open('output/prompts.txt', 'a') as f:\n",
    "    f.write('Q: ' + query + '\\n')\n",
    "    f.write('A: ' + result + '\\n')\n",
    "\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
